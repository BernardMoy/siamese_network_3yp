{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 16:56:22.313789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 16:56:22.394450: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 16:56:22.416199: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 16:56:23.331549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:\n",
      "2025-02-10 16:56:23.331602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:\n",
      "2025-02-10 16:56:23.331606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 16:56:25.836764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:25.845513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:25.845612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "!source /etc/profile.d/modules.sh\n",
    "!module load CUDA/11.2\n",
    "!export PATH=/local/java/cuda-11.2/bin:$PATH\n",
    "!export LD_LIBRARY_PATH=/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:$LD_LIBRARY_PATH  # this line is needed for it to recognise gpu devices -- run this in the terminal\n",
    "!export CUDA_HOME=/local/java/cuda-11.2\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, Dropout, GlobalAveragePooling2D, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "print(tf.__version__)  # 2.12.0\n",
    "print(tf.config.list_physical_devices('GPU'))  # should show gpu available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 16:56:25.857151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 16:56:25.857829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:25.857982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:25.858045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:26.163293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:26.163429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:26.163496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 16:56:26.163560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9580 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image_path):\n",
    "    # read the file \n",
    "    raw = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_image(raw, expand_animations=False, channels = 3)\n",
    "    img = tf.image.resize(img, size = (224, 224), preserve_aspect_ratio=True)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, 224, 224)\n",
    "    img = tf.cast(img, tf.float32)/255.0\n",
    "    return img \n",
    "\n",
    "def preprocess_pair(pair):\n",
    "    imgA = preprocess(pair[0])\n",
    "    imgB = preprocess(pair[1])\n",
    "    return (imgA, imgB)\n",
    "\n",
    "class RandomInvert(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_value = 255, factor=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def call(self, x):\n",
    "        if  tf.random.uniform([]) < self.factor:\n",
    "            x = (self.max_value - x)\n",
    "        return x\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomInvert(max_value = 1.0),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation((-0.4, 0.4)),\n",
    "    tf.keras.layers.RandomBrightness(factor=(-0.2, 0.2), value_range=(0., 1.)),\n",
    "    tf.keras.layers.GaussianNoise(0.005),\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.4, 0.4)),\n",
    "    tf.keras.layers.RandomContrast(factor=(0.1, 0.9)),\n",
    "    tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATION = 2\n",
    "MARGIN = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_pairs, val_pairs, train_labels, val_labels = train_test_split(\\n    pairs, labels, test_size=0.3, random_state=42\\n)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into training and validation dataset\n",
    "\"\"\"\n",
    "train_pairs, val_pairs, train_labels, val_labels = train_test_split(\n",
    "    pairs, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 96 images.\n",
      "8 classes:  ['wallet' 'alarm_clock' 'water_bottle' 'camera' 'pencil_case'\n",
      " 'digital_watch' 'backpack' 'mouse']\n",
      "74\n",
      "74\n",
      "22\n",
      "22\n",
      "['train_separated/wallet/20250204_204354.jpg', 'train_separated/wallet/20250131_001416.jpg', 'train_separated/wallet/20250204_203202.jpg', 'train_separated/wallet/20250131_001405.jpg']\n",
      "[0, 0, 0, 0]\n",
      "['train_separated/wallet/sg-11134201-7rbki-lqczx080rksn43.jpeg', 'train_separated/wallet/20250131_001352.jpg', 'train_separated/alarm_clock/20250204_203139.jpg', 'train_separated/alarm_clock/20250204_171523.jpg']\n",
      "[0, 0, 1, 1]\n",
      "74\n",
      "22\n",
      "80\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dataset_path = \"train_separated\"\n",
    "\n",
    "files = [os.path.join(r,file) for r,d,f in os.walk(dataset_path) for file in f]\n",
    "\n",
    "file_size = len(files)\n",
    "\n",
    "print(\"We have \" + str(file_size) + \" images.\")\n",
    "\n",
    "random.shuffle(files)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def make_instances(files, classes = []):\n",
    "    labels = []\n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "        clazz = file.split(\"/\")[-2]\n",
    "        \n",
    "        if classes.count(clazz):\n",
    "            label = classes.index(clazz)\n",
    "        else:\n",
    "            label = len(classes)\n",
    "            classes.append(clazz)\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(labels), np.array(classes)\n",
    "\n",
    "labels, classes = make_instances(files)\n",
    "CLASSES_SIZE = len(classes)\n",
    "\n",
    "print(str(CLASSES_SIZE) + \" classes: \", classes)\n",
    "\n",
    "training_files = []\n",
    "training_labels = []\n",
    "validation_files = []\n",
    "validation_labels = []\n",
    "\n",
    "for label in range(CLASSES_SIZE):\n",
    "    indexes = np.where(labels == label)[0]\n",
    "\n",
    "    threshold = len(indexes) * 80 // 100\n",
    "\n",
    "    training_indexes = indexes[0:threshold]\n",
    "    training_files_for_class = [files[i] for i in training_indexes]\n",
    "\n",
    "    training_files.extend(training_files_for_class)\n",
    "    training_labels.extend([label] * len(training_files_for_class))\n",
    "\n",
    "    validation_indexes = indexes[threshold:]\n",
    "    validation_files_for_class = [files[i] for i in validation_indexes]\n",
    "\n",
    "    validation_files.extend(validation_files_for_class)\n",
    "    validation_labels.extend([label] * len(validation_files_for_class))\n",
    "\n",
    "print(len(training_files))\n",
    "print(len(training_labels))\n",
    "print(len(validation_files))\n",
    "print(len(validation_labels))\n",
    "\n",
    "print(training_files[0:4])\n",
    "print(training_labels[0:4])\n",
    "\n",
    "print(validation_files[0:4])\n",
    "print(validation_labels[0:4])\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    n = min([len(digit_indices[d]) for d in range(CLASSES_SIZE)]) - 1\n",
    "    \n",
    "    for d in range(CLASSES_SIZE):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, CLASSES_SIZE)\n",
    "            dn = (d + inc) % CLASSES_SIZE\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "            \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_pairs_on_set(images, labels):\n",
    "    \n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(CLASSES_SIZE)]\n",
    "    pairs, y = create_pairs(images, digit_indices)\n",
    "    y = y.astype('float32')\n",
    "    \n",
    "    return pairs, y\n",
    "\n",
    "training_files = np.array(training_files)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "validation_files = np.array(validation_files)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "\n",
    "training_pairs, training_pairs_labels = create_pairs_on_set(training_files, training_labels)\n",
    "validation_pairs, validation_pairs_labels = create_pairs_on_set(validation_files, validation_labels)\n",
    "\n",
    "print(len(training_files))\n",
    "print(len(validation_files))\n",
    "print(len(training_pairs))\n",
    "print(len(validation_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "def build_training_dataset():\n",
    "\n",
    "    pairs_tensor = tf.convert_to_tensor(training_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(training_pairs_labels)\n",
    "\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    result = result.map(lambda pair, label: (preprocess_pair(pair), label))\n",
    "    result = result.shuffle(128, reshuffle_each_iteration=True)\n",
    "    result = result.repeat()\n",
    "    result = result.batch(BATCH_SIZE_TRAIN)\n",
    "    result = result.map(lambda pair, y: ((data_augmentation(pair[0], training=True),data_augmentation(pair[1], training=True)), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result\n",
    "\n",
    "train_dataset = build_training_dataset()\n",
    "\n",
    "def build_validation_dataset():\n",
    "\n",
    "    pairs_tensor = tf.convert_to_tensor(validation_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(validation_pairs_labels)\n",
    "\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    result = result.map(lambda pair, label: (preprocess_pair(pair), label))\n",
    "    result = result.batch(BATCH_SIZE_VALIDATION)\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result\n",
    "\n",
    "validation_dataset = build_validation_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_squared = K.sum(K.square(x-y), axis = 1, keepdims= True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make embedding\n",
    "embedding is each sub, identical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inputs = tf.keras.layers.Input(INPUT_SHAPE)\n",
    "    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=INPUT_SHAPE, include_top=False, weights='imagenet')\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable =  False\n",
    "          \n",
    "    x = base_model(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs=tf.keras.layers.Dense(64)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    # create embedding\n",
    "    embedding = make_embedding()\n",
    "\n",
    "    # create the same embedding for the two inputs \n",
    "    input_a = Input(shape = INPUT_SHAPE, name = \"first_image\")\n",
    "    input_b = Input(shape = INPUT_SHAPE, name = \"second_image\")\n",
    "\n",
    "    embedding_a = embedding(input_a)\n",
    "    embedding_b = embedding(input_b)\n",
    "\n",
    "    # Create the final euclidean distance layer\n",
    "    output = Lambda(euclidean_distance, name = \"distance\")([embedding_a, embedding_b])\n",
    "\n",
    "    return Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " first_image (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " second_image (InputLayer)      [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 64)           2339968     ['first_image[0][0]',            \n",
      "                                                                  'second_image[0][0]']           \n",
      "                                                                                                  \n",
      " distance (Lambda)              (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,339,968\n",
      "Trainable params: 1,121,984\n",
      "Non-trainable params: 1,217,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(MARGIN - y_pred, 0))\n",
    "    return (y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Precision(tf.keras.metrics.Precision):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)\n",
    "  \n",
    "class Custom_Recall(tf.keras.metrics.Recall):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)\n",
    "  \n",
    "class Custom_Accuracy(tf.keras.metrics.Accuracy):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 16:56:36.791948: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2025-02-10 16:56:37.199130: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 16:56:37.199503: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 16:56:37.199515: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2025-02-10 16:56:37.199870: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 16:56:37.199902: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/10 [===========>..................] - ETA: 0s - loss: 14.0492 - accuracy: 0.5312 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 16:56:37.472802: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 9.0049 - accuracy: 0.5000 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 \n",
      "Epoch 1: val_loss improved from inf to 68.36482, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 8s 289ms/step - loss: 9.0049 - accuracy: 0.5000 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 68.3648 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.2195 - accuracy: 0.5139 - custom__precision: 1.0000 - custom__recall: 0.0789       \n",
      "Epoch 2: val_loss improved from 68.36482 to 68.19321, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 4s 406ms/step - loss: 1.1156 - accuracy: 0.5250 - custom__precision: 0.7500 - custom__recall: 0.0750 - val_loss: 68.1932 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6909 - accuracy: 0.5556 - custom__precision: 0.6250 - custom__recall: 0.2778\n",
      "Epoch 3: val_loss improved from 68.19321 to 64.15260, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.7303 - accuracy: 0.5250 - custom__precision: 0.5556 - custom__recall: 0.2500 - val_loss: 64.1526 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2777 - accuracy: 0.5556 - custom__precision: 0.5652 - custom__recall: 0.3714\n",
      "Epoch 4: val_loss improved from 64.15260 to 59.33361, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 160ms/step - loss: 0.2823 - accuracy: 0.5250 - custom__precision: 0.5357 - custom__recall: 0.3750 - val_loss: 59.3336 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.3750 - custom__precision: 0.4000 - custom__recall: 0.5000      \n",
      "Epoch 5: val_loss improved from 59.33361 to 53.31033, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.3689 - accuracy: 0.3750 - custom__precision: 0.4000 - custom__recall: 0.5000 - val_loss: 53.3103 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2515 - accuracy: 0.5556 - custom__precision: 0.5682 - custom__recall: 0.6579\n",
      "Epoch 6: val_loss improved from 53.31033 to 48.91375, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 271ms/step - loss: 0.2421 - accuracy: 0.5750 - custom__precision: 0.5652 - custom__recall: 0.6500 - val_loss: 48.9137 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.4125 - custom__precision: 0.4286 - custom__recall: 0.5250\n",
      "Epoch 7: val_loss improved from 48.91375 to 43.90021, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2957 - accuracy: 0.4125 - custom__precision: 0.4286 - custom__recall: 0.5250 - val_loss: 43.9002 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.4875 - custom__precision: 0.4906 - custom__recall: 0.6500\n",
      "Epoch 8: val_loss improved from 43.90021 to 39.39822, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.2812 - accuracy: 0.4875 - custom__precision: 0.4906 - custom__recall: 0.6500 - val_loss: 39.3982 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4231 - accuracy: 0.5139 - custom__precision: 0.5000 - custom__recall: 0.4286\n",
      "Epoch 9: val_loss improved from 39.39822 to 33.35387, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.4300 - accuracy: 0.5250 - custom__precision: 0.5312 - custom__recall: 0.4250 - val_loss: 33.3539 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2190 - accuracy: 0.6389 - custom__precision: 0.6667 - custom__recall: 0.5556\n",
      "Epoch 10: val_loss improved from 33.35387 to 30.53727, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2777 - accuracy: 0.6250 - custom__precision: 0.6667 - custom__recall: 0.5000 - val_loss: 30.5373 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4436 - accuracy: 0.5278 - custom__precision: 0.5263 - custom__recall: 0.5556\n",
      "Epoch 11: val_loss improved from 30.53727 to 23.71338, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.4321 - accuracy: 0.5375 - custom__precision: 0.5385 - custom__recall: 0.5250 - val_loss: 23.7134 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.5625 - custom__precision: 0.5641 - custom__recall: 0.5500\n",
      "Epoch 12: val_loss improved from 23.71338 to 20.37179, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.3568 - accuracy: 0.5625 - custom__precision: 0.5641 - custom__recall: 0.5500 - val_loss: 20.3718 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3215 - accuracy: 0.4861 - custom__precision: 0.5000 - custom__recall: 0.4865\n",
      "Epoch 13: val_loss improved from 20.37179 to 16.74631, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.3206 - accuracy: 0.4875 - custom__precision: 0.4865 - custom__recall: 0.4500 - val_loss: 16.7463 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2917 - accuracy: 0.5556 - custom__precision: 0.5682 - custom__recall: 0.6579\n",
      "Epoch 14: val_loss improved from 16.74631 to 14.63850, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.3046 - accuracy: 0.5250 - custom__precision: 0.5192 - custom__recall: 0.6750 - val_loss: 14.6385 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.4500 - custom__precision: 0.4615 - custom__recall: 0.6000\n",
      "Epoch 15: val_loss improved from 14.63850 to 12.57569, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.2955 - accuracy: 0.4500 - custom__precision: 0.4615 - custom__recall: 0.6000 - val_loss: 12.5757 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.6000 - custom__precision: 0.6000 - custom__recall: 0.6000\n",
      "Epoch 16: val_loss improved from 12.57569 to 11.53485, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2793 - accuracy: 0.6000 - custom__precision: 0.6000 - custom__recall: 0.6000 - val_loss: 11.5349 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3411 - accuracy: 0.5417 - custom__precision: 0.5484 - custom__recall: 0.4722\n",
      "Epoch 17: val_loss improved from 11.53485 to 10.05813, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.4058 - accuracy: 0.5375 - custom__precision: 0.5429 - custom__recall: 0.4750 - val_loss: 10.0581 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5847 - accuracy: 0.4583 - custom__precision: 0.4643 - custom__recall: 0.3514      \n",
      "Epoch 18: val_loss improved from 10.05813 to 7.93949, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.5548 - accuracy: 0.4750 - custom__precision: 0.4688 - custom__recall: 0.3750 - val_loss: 7.9395 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3191 - accuracy: 0.5417 - custom__precision: 0.5455 - custom__recall: 0.5000\n",
      "Epoch 19: val_loss did not improve from 7.93949\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.3249 - accuracy: 0.5500 - custom__precision: 0.5588 - custom__recall: 0.4750 - val_loss: 8.3604 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.5125 - custom__precision: 0.5128 - custom__recall: 0.5000\n",
      "Epoch 20: val_loss improved from 7.93949 to 5.61404, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.3066 - accuracy: 0.5125 - custom__precision: 0.5128 - custom__recall: 0.5000 - val_loss: 5.6140 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.6375 - custom__precision: 0.6486 - custom__recall: 0.6000\n",
      "Epoch 21: val_loss improved from 5.61404 to 4.62337, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.2933 - accuracy: 0.6375 - custom__precision: 0.6486 - custom__recall: 0.6000 - val_loss: 4.6234 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.5625 - custom__precision: 0.5556 - custom__recall: 0.6250\n",
      "Epoch 22: val_loss improved from 4.62337 to 3.72844, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.3333 - accuracy: 0.5625 - custom__precision: 0.5556 - custom__recall: 0.6250 - val_loss: 3.7284 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.5500 - custom__precision: 0.5370 - custom__recall: 0.7250\n",
      "Epoch 23: val_loss improved from 3.72844 to 3.29238, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 162ms/step - loss: 0.2912 - accuracy: 0.5500 - custom__precision: 0.5370 - custom__recall: 0.7250 - val_loss: 3.2924 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.5750 - custom__precision: 0.5600 - custom__recall: 0.7000\n",
      "Epoch 24: val_loss improved from 3.29238 to 3.27582, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.2375 - accuracy: 0.5750 - custom__precision: 0.5600 - custom__recall: 0.7000 - val_loss: 3.2758 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.5750 - custom__precision: 0.5833 - custom__recall: 0.5250\n",
      "Epoch 25: val_loss improved from 3.27582 to 2.24258, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.2474 - accuracy: 0.5750 - custom__precision: 0.5833 - custom__recall: 0.5250 - val_loss: 2.2426 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2215 - accuracy: 0.6111 - custom__precision: 0.6250 - custom__recall: 0.6579\n",
      "Epoch 26: val_loss improved from 2.24258 to 1.93648, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.2171 - accuracy: 0.6250 - custom__precision: 0.6136 - custom__recall: 0.6750 - val_loss: 1.9365 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.5875 - custom__precision: 0.5745 - custom__recall: 0.6750\n",
      "Epoch 27: val_loss improved from 1.93648 to 1.60637, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2783 - accuracy: 0.5875 - custom__precision: 0.5745 - custom__recall: 0.6750 - val_loss: 1.6064 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.6625 - custom__precision: 0.6757 - custom__recall: 0.6250\n",
      "Epoch 28: val_loss did not improve from 1.60637\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 0.2772 - accuracy: 0.6625 - custom__precision: 0.6757 - custom__recall: 0.6250 - val_loss: 1.6590 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.5625 - custom__precision: 0.5676 - custom__recall: 0.5250\n",
      "Epoch 29: val_loss improved from 1.60637 to 1.26435, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2662 - accuracy: 0.5625 - custom__precision: 0.5676 - custom__recall: 0.5250 - val_loss: 1.2644 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.6375 - custom__precision: 0.6078 - custom__recall: 0.7750\n",
      "Epoch 30: val_loss did not improve from 1.26435\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 0.2529 - accuracy: 0.6375 - custom__precision: 0.6078 - custom__recall: 0.7750 - val_loss: 1.7517 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.6375 - custom__precision: 0.6667 - custom__recall: 0.5500\n",
      "Epoch 31: val_loss did not improve from 1.26435\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.3446 - accuracy: 0.6375 - custom__precision: 0.6667 - custom__recall: 0.5500 - val_loss: 1.8521 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.5250 - custom__precision: 0.5250 - custom__recall: 0.5250\n",
      "Epoch 32: val_loss did not improve from 1.26435\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.3261 - accuracy: 0.5250 - custom__precision: 0.5250 - custom__recall: 0.5250 - val_loss: 1.6437 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2538 - accuracy: 0.5000 - custom__precision: 0.4865 - custom__recall: 0.5806      \n",
      "Epoch 33: val_loss improved from 1.26435 to 1.15416, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.2631 - accuracy: 0.4875 - custom__precision: 0.4898 - custom__recall: 0.6000 - val_loss: 1.1542 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.5625 - custom__precision: 0.5556 - custom__recall: 0.6250\n",
      "Epoch 34: val_loss improved from 1.15416 to 0.88710, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.2603 - accuracy: 0.5625 - custom__precision: 0.5556 - custom__recall: 0.6250 - val_loss: 0.8871 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500\n",
      "Epoch 35: val_loss improved from 0.88710 to 0.84266, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 5s 527ms/step - loss: 0.2615 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500 - val_loss: 0.8427 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.5625 - custom__precision: 0.5472 - custom__recall: 0.7250\n",
      "Epoch 36: val_loss did not improve from 0.84266\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2476 - accuracy: 0.5625 - custom__precision: 0.5472 - custom__recall: 0.7250 - val_loss: 0.9809 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.5750 - custom__precision: 0.5789 - custom__recall: 0.5500\n",
      "Epoch 37: val_loss improved from 0.84266 to 0.80090, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4125 - accuracy: 0.5750 - custom__precision: 0.5789 - custom__recall: 0.5500 - val_loss: 0.8009 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.6250 - custom__precision: 0.6562 - custom__recall: 0.5250\n",
      "Epoch 38: val_loss did not improve from 0.80090\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.3781 - accuracy: 0.6250 - custom__precision: 0.6562 - custom__recall: 0.5250 - val_loss: 0.8790 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.5625 - custom__precision: 0.5490 - custom__recall: 0.7000\n",
      "Epoch 39: val_loss did not improve from 0.80090\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.3678 - accuracy: 0.5625 - custom__precision: 0.5490 - custom__recall: 0.7000 - val_loss: 1.0617 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.4750 - custom__precision: 0.4737 - custom__recall: 0.4500      \n",
      "Epoch 40: val_loss improved from 0.80090 to 0.63390, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 120ms/step - loss: 0.4163 - accuracy: 0.4750 - custom__precision: 0.4737 - custom__recall: 0.4500 - val_loss: 0.6339 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.6000 - custom__precision: 0.5833 - custom__recall: 0.7000\n",
      "Epoch 41: val_loss improved from 0.63390 to 0.46310, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.2693 - accuracy: 0.6000 - custom__precision: 0.5833 - custom__recall: 0.7000 - val_loss: 0.4631 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2643 - accuracy: 0.5625 - custom__precision: 0.5581 - custom__recall: 0.6000\n",
      "Epoch 42: val_loss improved from 0.46310 to 0.37648, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.2643 - accuracy: 0.5625 - custom__precision: 0.5581 - custom__recall: 0.6000 - val_loss: 0.3765 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2718 - accuracy: 0.5750 - custom__precision: 0.5833 - custom__recall: 0.5250\n",
      "Epoch 43: val_loss improved from 0.37648 to 0.37620, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 151ms/step - loss: 0.2718 - accuracy: 0.5750 - custom__precision: 0.5833 - custom__recall: 0.5250 - val_loss: 0.3762 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.5250 - custom__precision: 0.5312 - custom__recall: 0.4250\n",
      "Epoch 44: val_loss did not improve from 0.37620\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.3175 - accuracy: 0.5250 - custom__precision: 0.5312 - custom__recall: 0.4250 - val_loss: 0.3846 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.6125 - custom__precision: 0.6000 - custom__recall: 0.6750\n",
      "Epoch 45: val_loss improved from 0.37620 to 0.31193, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.2495 - accuracy: 0.6125 - custom__precision: 0.6000 - custom__recall: 0.6750 - val_loss: 0.3119 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.6875 - custom__precision: 0.6531 - custom__recall: 0.8000\n",
      "Epoch 46: val_loss improved from 0.31193 to 0.28241, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.2147 - accuracy: 0.6875 - custom__precision: 0.6531 - custom__recall: 0.8000 - val_loss: 0.2824 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.6750 - custom__precision: 0.6346 - custom__recall: 0.8250\n",
      "Epoch 47: val_loss did not improve from 0.28241\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.2202 - accuracy: 0.6750 - custom__precision: 0.6346 - custom__recall: 0.8250 - val_loss: 0.4339 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 48/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2625 - accuracy: 0.5625 - custom__precision: 0.5278 - custom__recall: 0.6333\n",
      "Epoch 48: val_loss did not improve from 0.28241\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 0.2525 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500 - val_loss: 0.3231 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.6500 - custom__precision: 0.6304 - custom__recall: 0.7250\n",
      "Epoch 49: val_loss did not improve from 0.28241\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.2037 - accuracy: 0.6500 - custom__precision: 0.6304 - custom__recall: 0.7250 - val_loss: 0.3443 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.7125 - custom__precision: 0.7073 - custom__recall: 0.7250\n",
      "Epoch 50: val_loss did not improve from 0.28241\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.2218 - accuracy: 0.7125 - custom__precision: 0.7073 - custom__recall: 0.7250 - val_loss: 0.3115 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.6000 - custom__precision: 0.5870 - custom__recall: 0.6750\n",
      "Epoch 51: val_loss improved from 0.28241 to 0.24952, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 151ms/step - loss: 0.2579 - accuracy: 0.6000 - custom__precision: 0.5870 - custom__recall: 0.6750 - val_loss: 0.2495 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.7250 - custom__precision: 0.7647 - custom__recall: 0.6500\n",
      "Epoch 52: val_loss improved from 0.24952 to 0.22252, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2360 - accuracy: 0.7250 - custom__precision: 0.7647 - custom__recall: 0.6500 - val_loss: 0.2225 - val_accuracy: 0.7500 - val_custom__precision: 1.0000 - val_custom__recall: 0.5000\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.6000 - custom__precision: 0.6053 - custom__recall: 0.5750\n",
      "Epoch 53: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 0.2494 - accuracy: 0.6000 - custom__precision: 0.6053 - custom__recall: 0.5750 - val_loss: 0.2641 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.7000 - custom__precision: 0.6905 - custom__recall: 0.7250\n",
      "Epoch 54: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 0.2405 - accuracy: 0.7000 - custom__precision: 0.6905 - custom__recall: 0.7250 - val_loss: 0.2618 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.7125 - custom__precision: 0.7073 - custom__recall: 0.7250\n",
      "Epoch 55: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.2256 - accuracy: 0.7125 - custom__precision: 0.7073 - custom__recall: 0.7250 - val_loss: 0.3017 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.7000 - custom__precision: 0.6667 - custom__recall: 0.8000\n",
      "Epoch 56: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.1889 - accuracy: 0.7000 - custom__precision: 0.6667 - custom__recall: 0.8000 - val_loss: 0.3728 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.6625 - custom__precision: 0.6667 - custom__recall: 0.6500\n",
      "Epoch 57: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.2329 - accuracy: 0.6625 - custom__precision: 0.6667 - custom__recall: 0.6500 - val_loss: 0.3237 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.6625 - custom__precision: 0.6970 - custom__recall: 0.5750\n",
      "Epoch 58: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2286 - accuracy: 0.6625 - custom__precision: 0.6970 - custom__recall: 0.5750 - val_loss: 0.2367 - val_accuracy: 0.5625 - val_custom__precision: 0.6000 - val_custom__recall: 0.3750\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.6375 - custom__precision: 0.6571 - custom__recall: 0.5750\n",
      "Epoch 59: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.2735 - accuracy: 0.6375 - custom__precision: 0.6571 - custom__recall: 0.5750 - val_loss: 0.3254 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.6375 - custom__precision: 0.6222 - custom__recall: 0.7000\n",
      "Epoch 60: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2274 - accuracy: 0.6375 - custom__precision: 0.6222 - custom__recall: 0.7000 - val_loss: 0.3250 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 61/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1918 - accuracy: 0.7500 - custom__precision: 0.7317 - custom__recall: 0.8108\n",
      "Epoch 61: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.1874 - accuracy: 0.7500 - custom__precision: 0.7381 - custom__recall: 0.7750 - val_loss: 0.6013 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.6500 - custom__precision: 0.7143 - custom__recall: 0.5000\n",
      "Epoch 62: val_loss did not improve from 0.22252\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.2444 - accuracy: 0.6500 - custom__precision: 0.7143 - custom__recall: 0.5000 - val_loss: 0.2267 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 63/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.3342 - accuracy: 0.5312 - custom__precision: 0.5000 - custom__recall: 0.4000\n",
      "Epoch 63: val_loss improved from 0.22252 to 0.20847, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.3013 - accuracy: 0.5625 - custom__precision: 0.5806 - custom__recall: 0.4500 - val_loss: 0.2085 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.3750\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.6625 - custom__precision: 0.6667 - custom__recall: 0.6500\n",
      "Epoch 64: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.3121 - accuracy: 0.6625 - custom__precision: 0.6667 - custom__recall: 0.6500 - val_loss: 0.5206 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.6375 - custom__precision: 0.6667 - custom__recall: 0.5500\n",
      "Epoch 65: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.2538 - accuracy: 0.6375 - custom__precision: 0.6667 - custom__recall: 0.5500 - val_loss: 0.3994 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.6875 - custom__precision: 0.7586 - custom__recall: 0.5500\n",
      "Epoch 66: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.2212 - accuracy: 0.6875 - custom__precision: 0.7586 - custom__recall: 0.5500 - val_loss: 0.4258 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 67/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2246 - accuracy: 0.6944 - custom__precision: 0.6667 - custom__recall: 0.7059\n",
      "Epoch 67: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2384 - accuracy: 0.6750 - custom__precision: 0.6842 - custom__recall: 0.6500 - val_loss: 0.4765 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 68/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1934 - accuracy: 0.7969 - custom__precision: 0.8667 - custom__recall: 0.7429\n",
      "Epoch 68: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2085 - accuracy: 0.7500 - custom__precision: 0.8125 - custom__recall: 0.6500 - val_loss: 0.4897 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 69/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1858 - accuracy: 0.6719 - custom__precision: 0.6552 - custom__recall: 0.6333\n",
      "Epoch 69: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.2026 - accuracy: 0.6500 - custom__precision: 0.6667 - custom__recall: 0.6000 - val_loss: 0.2821 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.7000 - custom__precision: 0.7000 - custom__recall: 0.7000\n",
      "Epoch 70: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1853 - accuracy: 0.7000 - custom__precision: 0.7000 - custom__recall: 0.7000 - val_loss: 0.3001 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.7875 - custom__precision: 0.8108 - custom__recall: 0.7500\n",
      "Epoch 71: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1671 - accuracy: 0.7875 - custom__precision: 0.8108 - custom__recall: 0.7500 - val_loss: 0.2610 - val_accuracy: 0.4375 - val_custom__precision: 0.4000 - val_custom__recall: 0.2500\n",
      "Epoch 72/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1812 - accuracy: 0.7188 - custom__precision: 0.7188 - custom__recall: 0.7188\n",
      "Epoch 72: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.1635 - accuracy: 0.7500 - custom__precision: 0.7381 - custom__recall: 0.7750 - val_loss: 0.2250 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.5000\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.7250 - custom__precision: 0.7368 - custom__recall: 0.7000\n",
      "Epoch 73: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.1733 - accuracy: 0.7250 - custom__precision: 0.7368 - custom__recall: 0.7000 - val_loss: 0.2503 - val_accuracy: 0.3750 - val_custom__precision: 0.4000 - val_custom__recall: 0.5000\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.7625 - custom__precision: 0.7442 - custom__recall: 0.8000\n",
      "Epoch 74: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1837 - accuracy: 0.7625 - custom__precision: 0.7442 - custom__recall: 0.8000 - val_loss: 0.2542 - val_accuracy: 0.6875 - val_custom__precision: 0.8000 - val_custom__recall: 0.5000\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.7625 - custom__precision: 0.8182 - custom__recall: 0.6750\n",
      "Epoch 75: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.2175 - accuracy: 0.7625 - custom__precision: 0.8182 - custom__recall: 0.6750 - val_loss: 0.2448 - val_accuracy: 0.5625 - val_custom__precision: 0.5455 - val_custom__recall: 0.7500\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.7375 - custom__precision: 0.7879 - custom__recall: 0.6500\n",
      "Epoch 76: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 66ms/step - loss: 0.1866 - accuracy: 0.7375 - custom__precision: 0.7879 - custom__recall: 0.6500 - val_loss: 0.2578 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.6250\n",
      "Epoch 77/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.7500 - custom__precision: 0.7561 - custom__recall: 0.7949\n",
      "Epoch 77: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.1760 - accuracy: 0.7500 - custom__precision: 0.7273 - custom__recall: 0.8000 - val_loss: 0.2448 - val_accuracy: 0.6250 - val_custom__precision: 0.6667 - val_custom__recall: 0.5000\n",
      "Epoch 78/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1492 - accuracy: 0.7778 - custom__precision: 0.7619 - custom__recall: 0.8421\n",
      "Epoch 78: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.1551 - accuracy: 0.7750 - custom__precision: 0.7500 - custom__recall: 0.8250 - val_loss: 0.2741 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.6875 - custom__precision: 0.6744 - custom__recall: 0.7250      \n",
      "Epoch 79: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.2298 - accuracy: 0.6875 - custom__precision: 0.6744 - custom__recall: 0.7250 - val_loss: 0.2313 - val_accuracy: 0.6250 - val_custom__precision: 0.6250 - val_custom__recall: 0.6250\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.7250 - custom__precision: 0.6957 - custom__recall: 0.8000\n",
      "Epoch 80: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.1753 - accuracy: 0.7250 - custom__precision: 0.6957 - custom__recall: 0.8000 - val_loss: 0.2295 - val_accuracy: 0.5625 - val_custom__precision: 0.5714 - val_custom__recall: 0.5000\n",
      "Epoch 81/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1841 - accuracy: 0.7639 - custom__precision: 0.7714 - custom__recall: 0.7500\n",
      "Epoch 81: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.1776 - accuracy: 0.7750 - custom__precision: 0.7750 - custom__recall: 0.7750 - val_loss: 0.2641 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 82/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1739 - accuracy: 0.7361 - custom__precision: 0.8065 - custom__recall: 0.6579\n",
      "Epoch 82: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.1730 - accuracy: 0.7375 - custom__precision: 0.7879 - custom__recall: 0.6500 - val_loss: 0.4726 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 83/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.3171 - accuracy: 0.7344 - custom__precision: 0.8095 - custom__recall: 0.5667\n",
      "Epoch 83: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.3250 - accuracy: 0.7125 - custom__precision: 0.8148 - custom__recall: 0.5500 - val_loss: 0.4501 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 84/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2145 - accuracy: 0.6806 - custom__precision: 0.7407 - custom__recall: 0.5556\n",
      "Epoch 84: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2066 - accuracy: 0.7125 - custom__precision: 0.7742 - custom__recall: 0.6000 - val_loss: 0.2683 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.3750\n",
      "Epoch 85/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1678 - accuracy: 0.7917 - custom__precision: 0.8000 - custom__recall: 0.7778\n",
      "Epoch 85: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.1695 - accuracy: 0.7750 - custom__precision: 0.7895 - custom__recall: 0.7500 - val_loss: 0.2906 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.1250\n",
      "Epoch 86/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1464 - accuracy: 0.8056 - custom__precision: 0.7750 - custom__recall: 0.8611\n",
      "Epoch 86: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 0.1504 - accuracy: 0.8000 - custom__precision: 0.7857 - custom__recall: 0.8250 - val_loss: 0.2799 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.8000 - custom__precision: 0.7609 - custom__recall: 0.8750\n",
      "Epoch 87: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.1376 - accuracy: 0.8000 - custom__precision: 0.7609 - custom__recall: 0.8750 - val_loss: 0.2859 - val_accuracy: 0.5625 - val_custom__precision: 0.6000 - val_custom__recall: 0.3750\n",
      "Epoch 88/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1785 - accuracy: 0.7969 - custom__precision: 0.7879 - custom__recall: 0.8125\n",
      "Epoch 88: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.1829 - accuracy: 0.7750 - custom__precision: 0.7619 - custom__recall: 0.8000 - val_loss: 0.3874 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 89/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.1328 - accuracy: 0.8438 - custom__precision: 0.8378 - custom__recall: 0.8857\n",
      "Epoch 89: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.1422 - accuracy: 0.8250 - custom__precision: 0.7955 - custom__recall: 0.8750 - val_loss: 0.3854 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 90/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1588 - accuracy: 0.7500 - custom__precision: 0.7941 - custom__recall: 0.7105\n",
      "Epoch 90: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.1559 - accuracy: 0.7625 - custom__precision: 0.7838 - custom__recall: 0.7250 - val_loss: 0.2866 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.3750\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.7375 - custom__precision: 0.7021 - custom__recall: 0.8250\n",
      "Epoch 91: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.1955 - accuracy: 0.7375 - custom__precision: 0.7021 - custom__recall: 0.8250 - val_loss: 0.3598 - val_accuracy: 0.4375 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.7750 - custom__precision: 0.7750 - custom__recall: 0.7750\n",
      "Epoch 92: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.1787 - accuracy: 0.7750 - custom__precision: 0.7750 - custom__recall: 0.7750 - val_loss: 0.3002 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.8250 - custom__precision: 0.7826 - custom__recall: 0.9000\n",
      "Epoch 93: val_loss did not improve from 0.20847\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.1420 - accuracy: 0.8250 - custom__precision: 0.7826 - custom__recall: 0.9000 - val_loss: 0.2797 - val_accuracy: 0.4375 - val_custom__precision: 0.4286 - val_custom__recall: 0.3750\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "model_file = \"weights/best_fit.hdf5\"\n",
    "siamese_model.compile(loss=contrastive_loss, \n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=[Custom_Accuracy(), Custom_Precision(), Custom_Recall()]\n",
    "                      )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30, restore_best_weights = False)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "\n",
    "history = siamese_model.fit(train_dataset, \n",
    "                            steps_per_epoch=math.ceil(len(training_pairs) / BATCH_SIZE_TRAIN), \n",
    "                            validation_data=validation_dataset, \n",
    "                            epochs = EPOCHS,\n",
    "                            callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 565ms/step\n",
      "Distance: [0.36175942]\n",
      "Predicted: [ True]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Distance: [0.34498158]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.38567683]\n",
      "Predicted: [ True]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [1.0431907]\n",
      "Predicted: [False]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.7059416]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.5850276]\n",
      "Predicted: [False]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Distance: [0.6371614]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.43593052]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.5861082]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.2918038]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.522858]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.7158443]\n",
      "Predicted: [False]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.32832855]\n",
      "Predicted: [ True]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.34498158]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.6257538]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.5026407]\n",
      "Predicted: [False]\n",
      "Label: False\n"
     ]
    }
   ],
   "source": [
    "for index, pair in enumerate(validation_pairs):\n",
    "    imgA, imgB = preprocess_pair(pair)\n",
    "\n",
    "    # Add batch dimension\n",
    "    imgA = tf.expand_dims(imgA, axis=0)  # (1, 224, 224, 3)\n",
    "    imgB = tf.expand_dims(imgB, axis=0)  # (1, 224, 224, 3)\n",
    "\n",
    "    prediction = siamese_model.predict([imgA, imgB])  \n",
    "    print(f\"Distance: {prediction[0]}\")\n",
    "    print(f\"Predicted: {prediction[0] <= 0.5}\")\n",
    "    print(f\"Label: {bool(validation_pairs_labels[index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
