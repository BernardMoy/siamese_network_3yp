{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 14:12:11.859689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 14:12:11.947416: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 14:12:11.969822: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 14:12:13.507137: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:\n",
      "2025-02-10 14:12:13.507218: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:\n",
      "2025-02-10 14:12:13.507225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 14:12:17.698084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:17.706480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:17.706579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "!source /etc/profile.d/modules.sh\n",
    "!module load CUDA/11.2\n",
    "!export PATH=/local/java/cuda-11.2/bin:$PATH\n",
    "!export LD_LIBRARY_PATH=/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:$LD_LIBRARY_PATH  # this line is needed for it to recognise gpu devices -- run this in the terminal\n",
    "!export CUDA_HOME=/local/java/cuda-11.2\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, Dropout, GlobalAveragePooling2D, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "print(tf.__version__)  # 2.12.0\n",
    "print(tf.config.list_physical_devices('GPU'))  # should show gpu available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"train\"\n",
    "\n",
    "def create_pairs():\n",
    "    pairs = []\n",
    "    labels = [] \n",
    "\n",
    "    for category in os.listdir(TRAIN_PATH):\n",
    "        anchor_dir = os.path.join(TRAIN_PATH, category, \"anchor\")\n",
    "        positive_dir = os.path.join(TRAIN_PATH, category, \"positive\")\n",
    "        negative_dir = os.path.join(TRAIN_PATH, category, \"negative\")\n",
    "\n",
    "        anchor_list = [os.path.join(anchor_dir, f) for f in os.listdir(anchor_dir)]\n",
    "        positive_list = [os.path.join(positive_dir, f) for f in os.listdir(positive_dir)]\n",
    "        negative_list = [os.path.join(negative_dir, f) for f in os.listdir(negative_dir)]\n",
    "        \n",
    "        for a in anchor_list:\n",
    "            for p in positive_list:\n",
    "                pairs.append((a,p))\n",
    "                labels.append(1)\n",
    "            for n in negative_list:\n",
    "                pairs.append((a,n))\n",
    "                labels.append(0)\n",
    "    \n",
    "    # shuffle the dataset \n",
    "    combined = list(zip(pairs, labels))\n",
    "    random.shuffle(combined)\n",
    "    pairs, labels = zip(*combined)\n",
    "    \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "pairs, labels = create_pairs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    # read the file \n",
    "    raw = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_image(raw, expand_animations=False, channels = 3)\n",
    "    img = tf.image.resize(img, size = (224, 224), preserve_aspect_ratio=True)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, 224, 224)\n",
    "    img = tf.cast(img, tf.float32)/255.0\n",
    "    return img \n",
    "\n",
    "def preprocess_pair(pair):\n",
    "    imgA = preprocess(pair[0])\n",
    "    imgB = preprocess(pair[1])\n",
    "    return (imgA, imgB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATION = 2\n",
    "MARGIN = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation dataset\n",
    "train_pairs, val_pairs, train_labels, val_labels = train_test_split(\n",
    "    pairs, labels, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 14:12:17.800181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 14:12:17.801787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:17.802200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:17.802392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:18.102754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:18.102932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:18.103005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 14:12:18.103069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9680 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def build_training_dataset():\n",
    "    pairs_tensor = tf.convert_to_tensor(train_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(train_labels)\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    # preprocess the images \n",
    "    result = result.map(lambda pair, label: (preprocess_pair(pair), label))\n",
    "    result = result.batch(BATCH_SIZE_TRAIN)\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result \n",
    "\n",
    "def build_validation_dataset():\n",
    "    pairs_tensor = tf.convert_to_tensor(val_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(val_labels)\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    # preprocess the images \n",
    "    result = result.map(lambda pair, label: (preprocess_pair(pair), label))\n",
    "    result = result.batch(BATCH_SIZE_VALIDATION)\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result \n",
    "\n",
    "train_dataset = build_training_dataset()\n",
    "validation_dataset = build_validation_dataset()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_squared = K.sum(K.square(x-y), axis = 1, keepdims= True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make embedding\n",
    "embedding is each sub, identical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
    "    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "\n",
    "    # Only make the last few layers (0.1) trainable \n",
    "    base_model.trainable = True \n",
    "    limit = len(base_model.layers) - int(len(base_model.layers)*0.10)\n",
    "    for layer in base_model.layers[:limit]:\n",
    "        base_model.trainable = False\n",
    "\n",
    "    # create output \n",
    "    x = base_model(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(64)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    # create embedding\n",
    "    embedding = make_embedding()\n",
    "\n",
    "    # create the same embedding for the two inputs \n",
    "    input_a = Input(shape = INPUT_SHAPE, name = \"first_image\")\n",
    "    input_b = Input(shape = INPUT_SHAPE, name = \"second_image\")\n",
    "\n",
    "    embedding_a = embedding(input_a)\n",
    "    embedding_b = embedding(input_b)\n",
    "\n",
    "    # Create the final euclidean distance layer\n",
    "    output = Lambda(euclidean_distance, name = \"distance\")([embedding_a, embedding_b])\n",
    "\n",
    "    return Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " first_image (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " second_image (InputLayer)      [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 64)           2339968     ['first_image[0][0]',            \n",
      "                                                                  'second_image[0][0]']           \n",
      "                                                                                                  \n",
      " distance (Lambda)              (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,339,968\n",
      "Trainable params: 81,984\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)   # cast the 1 and 0 to float32\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(MARGIN-y_pred, 0))\n",
    "    return y_true*square_pred + (1-y_true)*margin_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Precision(tf.keras.metrics.Precision):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)\n",
    "  \n",
    "class Custom_Recall(tf.keras.metrics.Recall):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)\n",
    "  \n",
    "class Custom_Accuracy(tf.keras.metrics.Accuracy):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 14:12:22.535237: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2025-02-10 14:12:22.925508: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 14:12:22.925965: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 14:12:22.925972: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2025-02-10 14:12:22.926287: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 14:12:22.926309: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/107 [..............................] - ETA: 2s - loss: 29.8954 - accuracy: 0.4583 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 14:12:23.194180: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 12s 80ms/step - loss: 8.0060 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 3.2473 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.8993 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.9035 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.3849 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.5679 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 1.3117 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.4400 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2814 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.4088 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2958 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.3758 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2882 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.3887 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2968 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.3190 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 9/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2844 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2591 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.2999 - accuracy: 0.5387 - custom__precision: 1.0000 - custom__recall: 0.0025 - val_loss: 1.2600 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2763 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.3022 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2964 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2944 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2996 - accuracy: 0.5387 - custom__precision: 1.0000 - custom__recall: 0.0025 - val_loss: 1.1955 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2850 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2304 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.3008 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2390 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2879 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2342 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 1.2981 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1696 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 1.2813 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2214 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2883 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2221 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.2840 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2446 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 1.2843 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2018 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2820 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2419 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 1.2820 - accuracy: 0.5387 - custom__precision: 1.0000 - custom__recall: 0.0025 - val_loss: 1.2692 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "107/107 [==============================] - 12s 113ms/step - loss: 1.2996 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1966 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2748 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2176 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 26/50\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.2892 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2110 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 27/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2984 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1796 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 28/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2660 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1627 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 29/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2928 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2480 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 30/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2818 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1695 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 31/50\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.2900 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2507 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 32/50\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 1.2940 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1241 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 33/50\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 1.2804 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1548 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 34/50\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 1.2911 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2020 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 35/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2710 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1757 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 36/50\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 1.2900 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1647 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 37/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2863 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2131 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 38/50\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 1.2845 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1884 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 39/50\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 1.2917 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1193 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 40/50\n",
      "107/107 [==============================] - 12s 115ms/step - loss: 1.2889 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1181 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 41/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2669 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2022 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 42/50\n",
      "107/107 [==============================] - 11s 100ms/step - loss: 1.2961 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1682 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 43/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2747 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2076 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 44/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2851 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1861 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 45/50\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 1.2845 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2166 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 46/50\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 1.2804 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1497 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 47/50\n",
      "107/107 [==============================] - 9s 79ms/step - loss: 1.2798 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2100 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 48/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2948 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1306 - val_accuracy: 0.5383 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 49/50\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 1.2859 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.2092 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n",
      "Epoch 50/50\n",
      "107/107 [==============================] - 10s 95ms/step - loss: 1.2878 - accuracy: 0.5376 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 1.1485 - val_accuracy: 0.5410 - val_custom__precision: 1.0000 - val_custom__recall: 0.0059\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50 \n",
    "\n",
    "siamese_model.compile(loss=contrastive_loss, optimizer=tf.keras.optimizers.RMSprop(),metrics=[Custom_Accuracy(), Custom_Precision(), Custom_Recall()])\n",
    "history = siamese_model.fit(train_dataset, \n",
    "                            steps_per_epoch=math.ceil(len(train_pairs) / BATCH_SIZE_TRAIN), \n",
    "                            validation_data=validation_dataset, \n",
    "                            epochs = EPOCHS\n",
    "                            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
