{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:05:48.265434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 17:05:48.357360: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 17:05:48.379938: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 17:05:50.016571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:\n",
      "2025-02-10 17:05:50.016659: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:\n",
      "2025-02-10 17:05:50.016667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:05:54.453536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.462042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.462141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "!source /etc/profile.d/modules.sh\n",
    "!module load CUDA/11.2\n",
    "!export PATH=/local/java/cuda-11.2/bin:$PATH\n",
    "!export LD_LIBRARY_PATH=/local/java/cuda-11.2/lib64:/local/java/cudnn-8.1_for_cuda_11.2/lib64:$LD_LIBRARY_PATH  # this line is needed for it to recognise gpu devices -- run this in the terminal\n",
    "!export CUDA_HOME=/local/java/cuda-11.2\n",
    "import os \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, Dropout, GlobalAveragePooling2D, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "print(tf.__version__)  # 2.10.0\n",
    "print(tf.config.list_physical_devices('GPU'))  # should show gpu available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:05:54.474252: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 17:05:54.475083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.475221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.475280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.776212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.776340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.776405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-10 17:05:54.776464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9418 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image_path):\n",
    "    # read the file \n",
    "    raw = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_image(raw, expand_animations=False, channels = 3)\n",
    "    img = tf.image.resize(img, size = (224, 224), preserve_aspect_ratio=True)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, 224, 224)\n",
    "    img = tf.cast(img, tf.float32)/255.0\n",
    "    return img \n",
    "\n",
    "def preprocess_pair(pair):\n",
    "    imgA = preprocess(pair[0])\n",
    "    imgB = preprocess(pair[1])\n",
    "    return (imgA, imgB)\n",
    "\n",
    "class RandomInvert(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_value = 255, factor=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def call(self, x):\n",
    "        if  tf.random.uniform([]) < self.factor:\n",
    "            x = (self.max_value - x)\n",
    "        return x\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomInvert(max_value = 1.0),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation((-0.4, 0.4)),\n",
    "    tf.keras.layers.RandomBrightness(factor=(-0.2, 0.2), value_range=(0., 1.)),\n",
    "    tf.keras.layers.GaussianNoise(0.005),\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.4, 0.4)),\n",
    "    tf.keras.layers.RandomContrast(factor=(0.1, 0.9)),\n",
    "    tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VALIDATION = 2\n",
    "MARGIN = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 96 images.\n",
      "8 classes:  ['pencil_case' 'camera' 'alarm_clock' 'water_bottle' 'backpack'\n",
      " 'digital_watch' 'mouse' 'wallet']\n",
      "74\n",
      "74\n",
      "22\n",
      "22\n",
      "['train_separated/pencil_case/20250204_193301.jpg', 'train_separated/pencil_case/LL83529-PN_Lihit-Lab-Lying-Pen-Pouch-PuniLabo-Penguin_P3.jpg', 'train_separated/pencil_case/200628.jpg', 'train_separated/pencil_case/200623.jpg']\n",
      "[0, 0, 0, 0]\n",
      "['train_separated/pencil_case/20250204_193312.jpg', 'train_separated/pencil_case/20250204_193242.jpg', 'train_separated/camera/20250204_203501.jpg', 'train_separated/camera/design-medium.jpg']\n",
      "[0, 0, 1, 1]\n",
      "74\n",
      "22\n",
      "80\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"train_separated\"\n",
    "\n",
    "files = [os.path.join(r,file) for r,d,f in os.walk(dataset_path) for file in f]\n",
    "file_size = len(files)\n",
    "print(\"We have \" + str(file_size) + \" images.\")\n",
    "random.shuffle(files)\n",
    "\n",
    "def make_instances(files, classes = []):\n",
    "    labels = []\n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "        clazz = file.split(\"/\")[-2]\n",
    "        \n",
    "        if classes.count(clazz):\n",
    "            label = classes.index(clazz)\n",
    "        else:\n",
    "            label = len(classes)\n",
    "            classes.append(clazz)\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(labels), np.array(classes)\n",
    "\n",
    "labels, classes = make_instances(files)\n",
    "CLASSES_SIZE = len(classes)\n",
    "\n",
    "print(str(CLASSES_SIZE) + \" classes: \", classes)\n",
    "\n",
    "training_files = []\n",
    "training_labels = []\n",
    "validation_files = []\n",
    "validation_labels = []\n",
    "\n",
    "for label in range(CLASSES_SIZE):\n",
    "    indexes = np.where(labels == label)[0]\n",
    "\n",
    "    threshold = len(indexes) * 80 // 100\n",
    "\n",
    "    training_indexes = indexes[0:threshold]\n",
    "    training_files_for_class = [files[i] for i in training_indexes]\n",
    "\n",
    "    training_files.extend(training_files_for_class)\n",
    "    training_labels.extend([label] * len(training_files_for_class))\n",
    "\n",
    "    validation_indexes = indexes[threshold:]\n",
    "    validation_files_for_class = [files[i] for i in validation_indexes]\n",
    "\n",
    "    validation_files.extend(validation_files_for_class)\n",
    "    validation_labels.extend([label] * len(validation_files_for_class))\n",
    "\n",
    "print(len(training_files))\n",
    "print(len(training_labels))\n",
    "print(len(validation_files))\n",
    "print(len(validation_labels))\n",
    "\n",
    "print(training_files[0:4])\n",
    "print(training_labels[0:4])\n",
    "\n",
    "print(validation_files[0:4])\n",
    "print(validation_labels[0:4])\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    n = min([len(digit_indices[d]) for d in range(CLASSES_SIZE)]) - 1\n",
    "    \n",
    "    for d in range(CLASSES_SIZE):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, CLASSES_SIZE)\n",
    "            dn = (d + inc) % CLASSES_SIZE\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "            \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_pairs_on_set(images, labels):\n",
    "    \n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(CLASSES_SIZE)]\n",
    "    pairs, y = create_pairs(images, digit_indices)\n",
    "    y = y.astype('float32')\n",
    "    \n",
    "    return pairs, y\n",
    "\n",
    "training_files = np.array(training_files)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "validation_files = np.array(validation_files)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "training_pairs, training_pairs_labels = create_pairs_on_set(training_files, training_labels)\n",
    "validation_pairs, validation_pairs_labels = create_pairs_on_set(validation_files, validation_labels)\n",
    "\n",
    "print(len(training_files))\n",
    "print(len(validation_files))\n",
    "print(len(training_pairs))\n",
    "print(len(validation_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "def build_training_dataset():\n",
    "\n",
    "    pairs_tensor = tf.convert_to_tensor(training_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(training_pairs_labels)\n",
    "\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    result = result.map(lambda pair, label: (preprocess_pair(pair), label))\n",
    "    result = result.shuffle(128, reshuffle_each_iteration=True)\n",
    "    result = result.repeat()\n",
    "    result = result.batch(BATCH_SIZE_TRAIN)\n",
    "    result = result.map(lambda pair, y: ((data_augmentation(pair[0], training=True),data_augmentation(pair[1], training=True)), y), \n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result\n",
    "\n",
    "train_dataset = build_training_dataset()\n",
    "\n",
    "def build_validation_dataset():\n",
    "\n",
    "    pairs_tensor = tf.convert_to_tensor(validation_pairs)\n",
    "    labels_tensor = tf.convert_to_tensor(validation_pairs_labels)\n",
    "\n",
    "    result = tf.data.Dataset.from_tensor_slices((pairs_tensor, labels_tensor))\n",
    "\n",
    "    result = result.map(lambda pair, label: (preprocess_pair(pair), label))\n",
    "    result = result.batch(BATCH_SIZE_VALIDATION)\n",
    "    result = result.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return result\n",
    "\n",
    "validation_dataset = build_validation_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_squared = K.sum(K.square(x-y), axis = 1, keepdims= True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make embedding\n",
    "embedding is each sub, identical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inputs = tf.keras.layers.Input(INPUT_SHAPE)\n",
    "    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=INPUT_SHAPE, include_top=False, weights='imagenet')\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    limit = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
    "    for layer in base_model.layers[:limit]:\n",
    "        layer.trainable =  False\n",
    "          \n",
    "    x = base_model(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs=tf.keras.layers.Dense(64)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    # create embedding\n",
    "    embedding = make_embedding()\n",
    "\n",
    "    # create the same embedding for the two inputs \n",
    "    input_a = Input(shape = INPUT_SHAPE, name = \"first_image\")\n",
    "    input_b = Input(shape = INPUT_SHAPE, name = \"second_image\")\n",
    "\n",
    "    embedding_a = embedding(input_a)\n",
    "    embedding_b = embedding(input_b)\n",
    "\n",
    "    # Create the final euclidean distance layer\n",
    "    output = Lambda(euclidean_distance, name = \"distance\")([embedding_a, embedding_b])\n",
    "\n",
    "    return Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " first_image (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " second_image (InputLayer)      [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 64)           2339968     ['first_image[0][0]',            \n",
      "                                                                  'second_image[0][0]']           \n",
      "                                                                                                  \n",
      " distance (Lambda)              (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,339,968\n",
      "Trainable params: 1,121,984\n",
      "Non-trainable params: 1,217,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(MARGIN - y_pred, 0))\n",
    "    return (y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Precision(tf.keras.metrics.Precision):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)\n",
    "  \n",
    "class Custom_Recall(tf.keras.metrics.Recall):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)\n",
    "  \n",
    "class Custom_Accuracy(tf.keras.metrics.Accuracy):\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_fix = tf.math.less(y_pred, 0.5) \n",
    "        y_pred_fix = tf.cast(y_pred_fix, y_pred.dtype)\n",
    "       \n",
    "        return super().update_state(y_true, y_pred_fix, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:06:05.544761: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2025-02-10 17:06:05.934798: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 17:06:05.935170: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 17:06:05.935180: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2025-02-10 17:06:05.935537: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-10 17:06:05.935581: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/10 [====================>.........] - ETA: 0s - loss: 13.2479 - accuracy: 0.4643 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 17:06:06.200141: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 9.9426 - accuracy: 0.5000 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 \n",
      "Epoch 1: val_loss improved from inf to 61.85041, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 7s 203ms/step - loss: 9.9426 - accuracy: 0.5000 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 61.8504 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.0510 - accuracy: 0.4861 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 61.85041 to 50.70310, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.9932 - accuracy: 0.4750 - custom__precision: 0.0000e+00 - custom__recall: 0.0000e+00 - val_loss: 50.7031 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3486 - accuracy: 0.5833 - custom__precision: 0.6111 - custom__recall: 0.3235      \n",
      "Epoch 3: val_loss improved from 50.70310 to 43.30556, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3394 - accuracy: 0.5750 - custom__precision: 0.6250 - custom__recall: 0.3750 - val_loss: 43.3056 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2942 - accuracy: 0.5278 - custom__precision: 0.5238 - custom__recall: 0.6111\n",
      "Epoch 4: val_loss improved from 43.30556 to 39.77066, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.3021 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.5750 - val_loss: 39.7707 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3001 - accuracy: 0.4861 - custom__precision: 0.4889 - custom__recall: 0.6111\n",
      "Epoch 5: val_loss improved from 39.77066 to 36.24749, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.3037 - accuracy: 0.4875 - custom__precision: 0.4898 - custom__recall: 0.6000 - val_loss: 36.2475 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2815 - accuracy: 0.5417 - custom__precision: 0.5116 - custom__recall: 0.6471\n",
      "Epoch 6: val_loss improved from 36.24749 to 32.72977, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.3068 - accuracy: 0.5375 - custom__precision: 0.5333 - custom__recall: 0.6000 - val_loss: 32.7298 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3444 - accuracy: 0.4722 - custom__precision: 0.4898 - custom__recall: 0.6486\n",
      "Epoch 7: val_loss improved from 32.72977 to 30.03805, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3355 - accuracy: 0.4875 - custom__precision: 0.4906 - custom__recall: 0.6500 - val_loss: 30.0380 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2832 - accuracy: 0.5972 - custom__precision: 0.5833 - custom__recall: 0.6000\n",
      "Epoch 8: val_loss improved from 30.03805 to 25.06280, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 145ms/step - loss: 0.2715 - accuracy: 0.6125 - custom__precision: 0.6154 - custom__recall: 0.6000 - val_loss: 25.0628 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3135 - accuracy: 0.4722 - custom__precision: 0.4545 - custom__recall: 0.5882\n",
      "Epoch 9: val_loss improved from 25.06280 to 21.42495, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.3111 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.6250 - val_loss: 21.4249 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3040 - accuracy: 0.4861 - custom__precision: 0.4545 - custom__recall: 0.4412      \n",
      "Epoch 10: val_loss improved from 21.42495 to 17.51490, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.2945 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.5000 - val_loss: 17.5149 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2645 - accuracy: 0.5972 - custom__precision: 0.5745 - custom__recall: 0.7500\n",
      "Epoch 11: val_loss improved from 17.51490 to 14.43879, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 268ms/step - loss: 0.2825 - accuracy: 0.5750 - custom__precision: 0.5625 - custom__recall: 0.6750 - val_loss: 14.4388 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.4750 - custom__precision: 0.4792 - custom__recall: 0.5750\n",
      "Epoch 12: val_loss improved from 14.43879 to 12.10068, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3078 - accuracy: 0.4750 - custom__precision: 0.4792 - custom__recall: 0.5750 - val_loss: 12.1007 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.4250 - custom__precision: 0.4423 - custom__recall: 0.5750\n",
      "Epoch 13: val_loss improved from 12.10068 to 10.34514, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 159ms/step - loss: 0.3464 - accuracy: 0.4250 - custom__precision: 0.4423 - custom__recall: 0.5750 - val_loss: 10.3451 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2980 - accuracy: 0.5694 - custom__precision: 0.5385 - custom__recall: 0.4242      \n",
      "Epoch 14: val_loss improved from 10.34514 to 8.29069, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2859 - accuracy: 0.5875 - custom__precision: 0.6061 - custom__recall: 0.5000 - val_loss: 8.2907 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3286 - accuracy: 0.5000 - custom__precision: 0.5278 - custom__recall: 0.5000\n",
      "Epoch 15: val_loss improved from 8.29069 to 7.09479, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.3250 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.5250 - val_loss: 7.0948 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3928 - accuracy: 0.5694 - custom__precision: 0.5429 - custom__recall: 0.5588\n",
      "Epoch 16: val_loss improved from 7.09479 to 5.90131, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.3844 - accuracy: 0.5625 - custom__precision: 0.5641 - custom__recall: 0.5500 - val_loss: 5.9013 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2846 - accuracy: 0.4375 - custom__precision: 0.4474 - custom__recall: 0.5312\n",
      "Epoch 17: val_loss improved from 5.90131 to 5.01799, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.2913 - accuracy: 0.4500 - custom__precision: 0.4600 - custom__recall: 0.5750 - val_loss: 5.0180 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2688 - accuracy: 0.6111 - custom__precision: 0.6154 - custom__recall: 0.6486\n",
      "Epoch 18: val_loss improved from 5.01799 to 4.14461, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 158ms/step - loss: 0.2773 - accuracy: 0.5625 - custom__precision: 0.5581 - custom__recall: 0.6000 - val_loss: 4.1446 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2988 - accuracy: 0.4861 - custom__precision: 0.4889 - custom__recall: 0.6111\n",
      "Epoch 19: val_loss improved from 4.14461 to 3.46089, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 133ms/step - loss: 0.2984 - accuracy: 0.4875 - custom__precision: 0.4902 - custom__recall: 0.6250 - val_loss: 3.4609 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2802 - accuracy: 0.5556 - custom__precision: 0.5400 - custom__recall: 0.7500\n",
      "Epoch 20: val_loss improved from 3.46089 to 3.00999, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 150ms/step - loss: 0.2861 - accuracy: 0.5500 - custom__precision: 0.5345 - custom__recall: 0.7750 - val_loss: 3.0100 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3052 - accuracy: 0.4444 - custom__precision: 0.4651 - custom__recall: 0.5405\n",
      "Epoch 21: val_loss improved from 3.00999 to 2.56656, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 148ms/step - loss: 0.3114 - accuracy: 0.4500 - custom__precision: 0.4600 - custom__recall: 0.5750 - val_loss: 2.5666 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3075 - accuracy: 0.4722 - custom__precision: 0.4688 - custom__recall: 0.4167\n",
      "Epoch 22: val_loss improved from 2.56656 to 2.01230, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 0.2976 - accuracy: 0.4875 - custom__precision: 0.4865 - custom__recall: 0.4500 - val_loss: 2.0123 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2961 - accuracy: 0.5278 - custom__precision: 0.5435 - custom__recall: 0.6579\n",
      "Epoch 23: val_loss improved from 2.01230 to 1.81482, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.2968 - accuracy: 0.5250 - custom__precision: 0.5192 - custom__recall: 0.6750 - val_loss: 1.8148 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2947 - accuracy: 0.5833 - custom__precision: 0.6296 - custom__recall: 0.4595\n",
      "Epoch 24: val_loss improved from 1.81482 to 1.56129, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 3s 362ms/step - loss: 0.2935 - accuracy: 0.5750 - custom__precision: 0.5882 - custom__recall: 0.5000 - val_loss: 1.5613 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500\n",
      "Epoch 25: val_loss did not improve from 1.56129\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.2525 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500 - val_loss: 1.6085 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 26/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2465 - accuracy: 0.6389 - custom__precision: 0.6053 - custom__recall: 0.6765\n",
      "Epoch 26: val_loss improved from 1.56129 to 1.19740, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 0.2479 - accuracy: 0.6375 - custom__precision: 0.6222 - custom__recall: 0.7000 - val_loss: 1.1974 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 27/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2678 - accuracy: 0.5694 - custom__precision: 0.5714 - custom__recall: 0.7368\n",
      "Epoch 27: val_loss improved from 1.19740 to 1.05899, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 157ms/step - loss: 0.2697 - accuracy: 0.5500 - custom__precision: 0.5370 - custom__recall: 0.7250 - val_loss: 1.0590 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 28/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3371 - accuracy: 0.3889 - custom__precision: 0.3846 - custom__recall: 0.4286\n",
      "Epoch 28: val_loss improved from 1.05899 to 0.89284, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.3308 - accuracy: 0.4125 - custom__precision: 0.4255 - custom__recall: 0.5000 - val_loss: 0.8928 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3243 - accuracy: 0.4750 - custom__precision: 0.4792 - custom__recall: 0.5750\n",
      "Epoch 29: val_loss improved from 0.89284 to 0.81394, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 0.3243 - accuracy: 0.4750 - custom__precision: 0.4792 - custom__recall: 0.5750 - val_loss: 0.8139 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.6250 - custom__precision: 0.6190 - custom__recall: 0.6500\n",
      "Epoch 30: val_loss improved from 0.81394 to 0.71367, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.2855 - accuracy: 0.6250 - custom__precision: 0.6190 - custom__recall: 0.6500 - val_loss: 0.7137 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.5250 - custom__precision: 0.5250 - custom__recall: 0.5250\n",
      "Epoch 31: val_loss improved from 0.71367 to 0.70701, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.2823 - accuracy: 0.5250 - custom__precision: 0.5250 - custom__recall: 0.5250 - val_loss: 0.7070 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.5375 - custom__precision: 0.5294 - custom__recall: 0.6750\n",
      "Epoch 32: val_loss did not improve from 0.70701\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2669 - accuracy: 0.5375 - custom__precision: 0.5294 - custom__recall: 0.6750 - val_loss: 0.8355 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.5750 - custom__precision: 0.5682 - custom__recall: 0.6250\n",
      "Epoch 33: val_loss improved from 0.70701 to 0.68170, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.2990 - accuracy: 0.5750 - custom__precision: 0.5682 - custom__recall: 0.6250 - val_loss: 0.6817 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 34/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2848 - accuracy: 0.5694 - custom__precision: 0.5882 - custom__recall: 0.5405\n",
      "Epoch 34: val_loss improved from 0.68170 to 0.55986, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 132ms/step - loss: 0.2953 - accuracy: 0.5375 - custom__precision: 0.5366 - custom__recall: 0.5500 - val_loss: 0.5599 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.6250\n",
      "Epoch 35: val_loss improved from 0.55986 to 0.44761, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 139ms/step - loss: 0.2962 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.6250 - val_loss: 0.4476 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.5625 - custom__precision: 0.5510 - custom__recall: 0.6750\n",
      "Epoch 36: val_loss improved from 0.44761 to 0.40514, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.2482 - accuracy: 0.5625 - custom__precision: 0.5510 - custom__recall: 0.6750 - val_loss: 0.4051 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.5750 - custom__precision: 0.5789 - custom__recall: 0.5500\n",
      "Epoch 37: val_loss improved from 0.40514 to 0.34256, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 0.2886 - accuracy: 0.5750 - custom__precision: 0.5789 - custom__recall: 0.5500 - val_loss: 0.3426 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 38/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2816 - accuracy: 0.5417 - custom__precision: 0.5349 - custom__recall: 0.6389\n",
      "Epoch 38: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 0.2810 - accuracy: 0.5375 - custom__precision: 0.5306 - custom__recall: 0.6500 - val_loss: 0.3458 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.4875 - custom__precision: 0.4889 - custom__recall: 0.5500\n",
      "Epoch 39: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3505 - accuracy: 0.4875 - custom__precision: 0.4889 - custom__recall: 0.5500 - val_loss: 0.5024 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 40/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3604 - accuracy: 0.5694 - custom__precision: 0.6176 - custom__recall: 0.5385\n",
      "Epoch 40: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.3411 - accuracy: 0.6000 - custom__precision: 0.6176 - custom__recall: 0.5250 - val_loss: 0.8099 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3380 - accuracy: 0.5139 - custom__precision: 0.5000 - custom__recall: 0.5429\n",
      "Epoch 41: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3235 - accuracy: 0.5250 - custom__precision: 0.5227 - custom__recall: 0.5750 - val_loss: 0.6031 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.6250 - custom__precision: 0.6250 - custom__recall: 0.6250\n",
      "Epoch 42: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.3182 - accuracy: 0.6250 - custom__precision: 0.6250 - custom__recall: 0.6250 - val_loss: 0.6353 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 43/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2548 - accuracy: 0.6250 - custom__precision: 0.6250 - custom__recall: 0.5714\n",
      "Epoch 43: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 134ms/step - loss: 0.2514 - accuracy: 0.6250 - custom__precision: 0.6316 - custom__recall: 0.6000 - val_loss: 0.3866 - val_accuracy: 0.5000 - val_custom__precision: 0.0000e+00 - val_custom__recall: 0.0000e+00\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.6000 - custom__precision: 0.5833 - custom__recall: 0.7000\n",
      "Epoch 44: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.2419 - accuracy: 0.6000 - custom__precision: 0.5833 - custom__recall: 0.7000 - val_loss: 0.3730 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 45/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2556 - accuracy: 0.6250 - custom__precision: 0.6429 - custom__recall: 0.5625\n",
      "Epoch 45: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.2481 - accuracy: 0.6375 - custom__precision: 0.6341 - custom__recall: 0.6500 - val_loss: 0.3729 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.6375 - custom__precision: 0.6222 - custom__recall: 0.7000\n",
      "Epoch 46: val_loss did not improve from 0.34256\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.2419 - accuracy: 0.6375 - custom__precision: 0.6222 - custom__recall: 0.7000 - val_loss: 0.4236 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.6250 - custom__precision: 0.6087 - custom__recall: 0.7000\n",
      "Epoch 47: val_loss improved from 0.34256 to 0.32539, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.2492 - accuracy: 0.6250 - custom__precision: 0.6087 - custom__recall: 0.7000 - val_loss: 0.3254 - val_accuracy: 0.5625 - val_custom__precision: 0.6667 - val_custom__recall: 0.2500\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.6500 - custom__precision: 0.6500 - custom__recall: 0.6500\n",
      "Epoch 48: val_loss did not improve from 0.32539\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 0.2532 - accuracy: 0.6500 - custom__precision: 0.6500 - custom__recall: 0.6500 - val_loss: 0.3530 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.2500\n",
      "Epoch 49/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2950 - accuracy: 0.6250 - custom__precision: 0.6552 - custom__recall: 0.5278\n",
      "Epoch 49: val_loss did not improve from 0.32539\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.2845 - accuracy: 0.6125 - custom__precision: 0.6452 - custom__recall: 0.5000 - val_loss: 0.3299 - val_accuracy: 0.5000 - val_custom__precision: 0.5000 - val_custom__recall: 0.2500\n",
      "Epoch 50/200\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3108 - accuracy: 0.5694 - custom__precision: 0.5500 - custom__recall: 0.6286\n",
      "Epoch 50: val_loss did not improve from 0.32539\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.2952 - accuracy: 0.5875 - custom__precision: 0.5778 - custom__recall: 0.6500 - val_loss: 0.5305 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.3500      \n",
      "Epoch 51: val_loss did not improve from 0.32539\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 0.4245 - accuracy: 0.5000 - custom__precision: 0.5000 - custom__recall: 0.3500 - val_loss: 0.4686 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 52/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2254 - accuracy: 0.6719 - custom__precision: 0.6667 - custom__recall: 0.6875\n",
      "Epoch 52: val_loss improved from 0.32539 to 0.30153, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 140ms/step - loss: 0.2457 - accuracy: 0.6625 - custom__precision: 0.6512 - custom__recall: 0.7000 - val_loss: 0.3015 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.6375 - custom__precision: 0.6279 - custom__recall: 0.6750\n",
      "Epoch 53: val_loss did not improve from 0.30153\n",
      "10/10 [==============================] - 1s 72ms/step - loss: 0.2366 - accuracy: 0.6375 - custom__precision: 0.6279 - custom__recall: 0.6750 - val_loss: 0.3194 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 54/200\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.2446 - accuracy: 0.5938 - custom__precision: 0.5526 - custom__recall: 0.7000\n",
      "Epoch 54: val_loss did not improve from 0.30153\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.2302 - accuracy: 0.6125 - custom__precision: 0.6000 - custom__recall: 0.6750 - val_loss: 0.4350 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.6375 - custom__precision: 0.6341 - custom__recall: 0.6500\n",
      "Epoch 55: val_loss improved from 0.30153 to 0.29985, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.2530 - accuracy: 0.6375 - custom__precision: 0.6341 - custom__recall: 0.6500 - val_loss: 0.2998 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3082 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500\n",
      "Epoch 56: val_loss did not improve from 0.29985\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.3082 - accuracy: 0.6000 - custom__precision: 0.5909 - custom__recall: 0.6500 - val_loss: 0.3412 - val_accuracy: 0.6250 - val_custom__precision: 0.7500 - val_custom__recall: 0.3750\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.6875 - custom__precision: 0.6596 - custom__recall: 0.7750\n",
      "Epoch 57: val_loss improved from 0.29985 to 0.28793, saving model to weights/best_fit.hdf5\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 0.2325 - accuracy: 0.6875 - custom__precision: 0.6596 - custom__recall: 0.7750 - val_loss: 0.2879 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.6750 - custom__precision: 0.6458 - custom__recall: 0.7750\n",
      "Epoch 58: val_loss did not improve from 0.28793\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.2085 - accuracy: 0.6750 - custom__precision: 0.6458 - custom__recall: 0.7750 - val_loss: 0.4844 - val_accuracy: 0.5625 - val_custom__precision: 0.6667 - val_custom__recall: 0.2500\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.7625 - custom__precision: 0.7442 - custom__recall: 0.8000\n",
      "Epoch 59: val_loss did not improve from 0.28793\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.1601 - accuracy: 0.7625 - custom__precision: 0.7442 - custom__recall: 0.8000 - val_loss: 0.3035 - val_accuracy: 0.6875 - val_custom__precision: 1.0000 - val_custom__recall: 0.3750\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.6875 - custom__precision: 0.6667 - custom__recall: 0.7500\n",
      "Epoch 60: val_loss did not improve from 0.28793\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.2015 - accuracy: 0.6875 - custom__precision: 0.6667 - custom__recall: 0.7500 - val_loss: 0.3310 - val_accuracy: 0.6250 - val_custom__precision: 1.0000 - val_custom__recall: 0.2500\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.6750 - custom__precision: 0.6522 - custom__recall: 0.7500\n",
      "Epoch 61: val_loss did not improve from 0.28793\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2105 - accuracy: 0.6750 - custom__precision: 0.6522 - custom__recall: 0.7500 - val_loss: 0.4241 - val_accuracy: 0.5625 - val_custom__precision: 1.0000 - val_custom__recall: 0.1250\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.6875 - custom__precision: 0.6667 - custom__recall: 0.7500\n",
      "Epoch 62: val_loss did not improve from 0.28793\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.2228 - accuracy: 0.6875 - custom__precision: 0.6667 - custom__recall: 0.7500 - val_loss: 0.3103 - val_accuracy: 0.6250 - val_custom__precision: 0.7500 - val_custom__recall: 0.3750\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.7750 - custom__precision: 0.7895 - custom__recall: 0.7500\n",
      "Epoch 63: val_loss improved from 0.28793 to 0.27605, saving model to weights/best_fit.hdf5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(model_file, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE_TRAIN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/engine/training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1621\u001b[0m     }\n\u001b[1;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/callbacks.py:1463\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs_since_last_save \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/callbacks.py:1528\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_weights(\n\u001b[1;32m   1523\u001b[0m             filepath,\n\u001b[1;32m   1524\u001b[0m             overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1525\u001b[0m             options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options,\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1528\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/engine/training.py:2698\u001b[0m, in \u001b[0;36mModel.save\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2643\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave\u001b[39m(\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2652\u001b[0m     save_traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2653\u001b[0m ):\n\u001b[1;32m   2655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[1;32m   2656\u001b[0m \n\u001b[1;32m   2657\u001b[0m \u001b[38;5;124;03m    Please see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2698\u001b[0m     \u001b[43msave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/saving/save.py:161\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    151\u001b[0m         model, sequential\u001b[38;5;241m.\u001b[39mSequential\n\u001b[1;32m    152\u001b[0m     ):\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model_to_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_optimizer\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mSharedObjectSavingScope():\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/keras/saving/hdf5_format.py:109\u001b[0m, in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dirpath):\n\u001b[1;32m    107\u001b[0m         tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mmakedirs(dirpath)\n\u001b[0;32m--> 109\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/tfvenv/lib64/python3.9/site-packages/h5py/_hl/files.py:241\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    239\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mcreate(name, h5f\u001b[38;5;241m.\u001b[39mACC_EXCL, fapl\u001b[38;5;241m=\u001b[39mfapl, fcpl\u001b[38;5;241m=\u001b[39mfcpl)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 241\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mACC_TRUNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:122\u001b[0m, in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5g.pyx:281\u001b[0m, in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5g.pyx:282\u001b[0m, in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "model_file = \"weights/best_fit.hdf5\"\n",
    "siamese_model.compile(loss=contrastive_loss, \n",
    "                      optimizer=tf.keras.optimizers.Adam(),\n",
    "                      metrics=[Custom_Accuracy(), Custom_Precision(), Custom_Recall()]\n",
    "                      )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 30, restore_best_weights = False)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "\n",
    "history = siamese_model.fit(train_dataset, \n",
    "                            steps_per_epoch=math.ceil(len(training_pairs) / BATCH_SIZE_TRAIN), \n",
    "                            validation_data=validation_dataset, \n",
    "                            epochs = EPOCHS,\n",
    "                            callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 565ms/step\n",
      "Distance: [0.36175942]\n",
      "Predicted: [ True]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Distance: [0.34498158]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.38567683]\n",
      "Predicted: [ True]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [1.0431907]\n",
      "Predicted: [False]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.7059416]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.5850276]\n",
      "Predicted: [False]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Distance: [0.6371614]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.43593052]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.5861082]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.2918038]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.522858]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.7158443]\n",
      "Predicted: [False]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.32832855]\n",
      "Predicted: [ True]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.34498158]\n",
      "Predicted: [ True]\n",
      "Label: False\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.6257538]\n",
      "Predicted: [False]\n",
      "Label: True\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Distance: [0.5026407]\n",
      "Predicted: [False]\n",
      "Label: False\n"
     ]
    }
   ],
   "source": [
    "for index, pair in enumerate(validation_pairs):\n",
    "    imgA, imgB = preprocess_pair(pair)\n",
    "\n",
    "    # Add batch dimension\n",
    "    imgA = tf.expand_dims(imgA, axis=0)  # (1, 224, 224, 3)\n",
    "    imgB = tf.expand_dims(imgB, axis=0)  # (1, 224, 224, 3)\n",
    "\n",
    "    prediction = siamese_model.predict([imgA, imgB])  \n",
    "    print(f\"Distance: {prediction[0]}\")\n",
    "    print(f\"Predicted: {prediction[0] <= 0.5}\")\n",
    "    print(f\"Label: {bool(validation_pairs_labels[index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
