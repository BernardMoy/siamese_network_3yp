{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images as (anchor, second_image, label)\n",
    "1 if second image is positive, 0 if negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "TRAIN_PATH = r\"C:\\Users\\holog\\Desktop\\machine_learning\\similarity\\train\"\n",
    "TEST_PATH = r\"C:\\Users\\holog\\Desktop\\machine_learning\\similarity\\test\"\n",
    "\n",
    "positive_pairs_train = []\n",
    "negative_pairs_train = []\n",
    "\n",
    "# Anchor images are in train/directory/anchor for each directory\n",
    "for category in os.listdir(TRAIN_PATH):\n",
    "    anchor_dir = os.path.join(TRAIN_PATH, category, \"anchor\")\n",
    "    positive_dir = os.path.join(TRAIN_PATH, category, \"positive\")\n",
    "    negative_dir = os.path.join(TRAIN_PATH, category, \"negative\")\n",
    "\n",
    "    anchor_list = [os.path.join(anchor_dir, f) for f in os.listdir(anchor_dir)]\n",
    "    positive_list = [os.path.join(positive_dir, f) for f in os.listdir(positive_dir)]\n",
    "    negative_list = [os.path.join(negative_dir, f) for f in os.listdir(negative_dir)]\n",
    "\n",
    "    # Within each category directory, match each anchor with each positive and negative \n",
    "    positive_pairs_train += [(a, p, 1) for a in anchor_list for p in positive_list]\n",
    "    negative_pairs_train += [(a, n, 0) for a in anchor_list for n in negative_list]\n",
    "\n",
    "data_raw_train = positive_pairs_train + negative_pairs_train \n",
    "\n",
    "# Do the same for test images\n",
    "positive_pairs_test = []\n",
    "negative_pairs_test = []\n",
    "\n",
    "test_path_positive = os.path.join(TEST_PATH, \"positive\")\n",
    "test_path_negative = os.path.join(TEST_PATH, \"negative\")\n",
    "\n",
    "for category in os.listdir(test_path_positive):\n",
    "    dirs = os.listdir(os.path.join(test_path_positive, category))\n",
    "    first_dir = os.path.join(test_path_positive, category, dirs[0])\n",
    "    second_dir = os.path.join(test_path_positive, category, dirs[1])\n",
    "    positive_pairs_test.append((category, first_dir, second_dir, 1))\n",
    "\n",
    "for category in os.listdir(test_path_negative):\n",
    "    dirs = os.listdir(os.path.join(test_path_negative, category))\n",
    "    first_dir = os.path.join(test_path_negative, category, dirs[0])\n",
    "    second_dir = os.path.join(test_path_negative, category, dirs[1])\n",
    "    negative_pairs_test.append((category, first_dir, second_dir, 0))\n",
    "\n",
    "data_raw_test = positive_pairs_test + negative_pairs_test\n",
    "\n",
    "data_raw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def preprocess(image_path):\n",
    "    byte_img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (105, 105))  # Resize to 105x105x3 (3 color channels)\n",
    "    img = img / 255.0  # Scale image between 0 and 1\n",
    "    return img \n",
    "\n",
    "# The first anchor image is shown\n",
    "test = preprocess(data_raw_train[0][0])\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labelled dataset (1 and 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to tf dataset \n",
    "def convert_to_tf_dataset(data_raw):\n",
    "    i1_paths, i2_paths, labels = zip(*data_raw)\n",
    "    i1_dataset = tf.data.Dataset.from_tensor_slices(list(i1_paths)).map(preprocess)  # Preprocess the images \n",
    "    i2_dataset = tf.data.Dataset.from_tensor_slices(list(i2_paths)).map(preprocess)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(list(labels))\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((i1_dataset, i2_dataset, label_dataset))\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(buffer_size=1024)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tf dataset \n",
    "dataset_train = convert_to_tf_dataset(data_raw_train)\n",
    "\n",
    "# Check \n",
    "samples = dataset_train.as_numpy_iterator()\n",
    "next = samples.next()\n",
    "print(next[2])  # next[0] is the anchor, next[1] is the positive, next[2] is the negative\n",
    "# Hence, if 1 is printed, the image is positive, else the image should be negative:\n",
    "plt.imshow(next[1])\n",
    "\n",
    "# Should show a different image everytime \n",
    "dataset_train  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the train_data and validation_data\n",
    "The data is split into 7:3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of anchors in each anchor dir * (Number of positives in each positive dir + Number of negatives in each negative dir) * Number of categories\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Split the train dataset into train data (7) and validation data (3)\n",
    "train_data = dataset_train.take(round(len(dataset_train)*.7))  # Take all train data\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "validation_data = dataset_train.skip(round(len(dataset_train)*.7))\n",
    "validation_data = validation_data.take(round(len(dataset_train)*.3))\n",
    "validation_data = validation_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.prefetch(8)\n",
    "\n",
    "# Print the length of train data and validation data\n",
    "print(len(train_data))\n",
    "print(len(validation_data))\n",
    "\n",
    "# Check\n",
    "train_sample = train_data.as_numpy_iterator().next()\n",
    "print(train_data)\n",
    "print(len(train_sample))  # 3\n",
    "print(len(train_sample[0]))  # = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, Lambda\n",
    "\n",
    "def make_embedding():\n",
    "    inp = Input(shape=(105, 105, 3))\n",
    "\n",
    "    c1 = Conv2D(64, (10, 10), activation=\"relu\")(inp)  # Convolution + ReLU\n",
    "    m1 = MaxPooling2D(64, (2,2), padding=\"same\")(c1)  # Max pooling\n",
    "\n",
    "    c2 = Conv2D(128, (7,7), activation=\"relu\")(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding=\"same\")(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (4,4), activation=\"relu\")(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding=\"same\")(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (4,4), activation=\"relu\")(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation = \"sigmoid\")(f1)   # Fully connected layer \n",
    "\n",
    "    return Model(inputs=[inp], outputs = [d1], name = \"embedding\")\n",
    "\n",
    "# Create model\n",
    "embedding = make_embedding()\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    \n",
    "    # L1 distance (Similarity calculation)\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)\n",
    "    \n",
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    # Get the input images\n",
    "    input_image = Input(name=\"input_img\", shape=(105, 105, 3))\n",
    "    validation_image = Input(name=\"validation_img\", shape=(105, 105, 3))\n",
    "\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = \"distance\"\n",
    "\n",
    "    # embedding() outputs a 4096 length array of feature vectors\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    # Compute L1 distance\n",
    "    output = Lambda(lambda x: tf.reduce_sum(tf.abs(x), axis=-1, keepdims=True))(distances)\n",
    "    # classifier = Dense(1, activation=\"sigmoid\")(distances)\n",
    "    \n",
    "    # Return the siamese model\n",
    "    model = Model(inputs=[input_image, validation_image], outputs=output, name=\"SiameseNetwork\")\n",
    "    return model \n",
    "\n",
    "\n",
    "# First goes through embedding (Hidden) layers, then passed to distance layer and finally dense (output) layer \n",
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up loss and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_cross_loss = tf.losses.BinaryCrossentropy()    # Loss function is binary cross entropy\n",
    "opt = tf.keras.optimizers.Adam(1e-4)   # Learning rate = 0.001\n",
    "\n",
    "margin = 1.0\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)  # Cast y true (Int) to float 32\n",
    "    loss = (1-y_true)*tf.square(y_pred) + y_true*tf.square(tf.maximum(margin-y_pred, 0))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "log_dir = f\"logs/train_{current_datetime}\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "checkpoint_dir = r\"C:\\Users\\holog\\Desktop\\machine_learning\\similarity\\training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model = siamese_model)  # siamese_model is the model created above \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build train step function\n",
    "used to train one batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_model is the model created above \n",
    "\n",
    "# Compile this function into tensorflow graph (@tf.function)\n",
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = batch[:2]  # [anchor, positive] or [anchor, negative]\n",
    "        y = batch[2]   # The label (0 or 1)\n",
    "\n",
    "        # Pass this to the siamese neural network \n",
    "        yhat = siamese_model(X, training=True)  # Predicted y, i.e. y-hat  (y^)\n",
    "        \n",
    "        # Calculate loss using contrastive loss\n",
    "        loss = contrastive_loss(y, yhat)\n",
    "\n",
    "    # Calculate gradients \n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "\n",
    "    # Calculate updated weights and then apply to the siamese model\n",
    "    opt.apply_gradients(\n",
    "        zip(grad, siamese_model.trainable_variables)\n",
    "    )\n",
    "\n",
    "    # return the loss \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # For each epoch, loop through each batch and run train steps \n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print(f\"Epoch {epoch} of {EPOCHS}\" + \"\\n\")\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "\n",
    "        # Loop through each batch\n",
    "        for index, batch in enumerate(data):\n",
    "            loss = train_step(batch)\n",
    "            progbar.update(index + 1)\n",
    "\n",
    "            # Log to tensorboard\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', loss, step=epoch * len(data) + index)\n",
    "        \n",
    "        # Save checkpoints \n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)  # \"ckpt\"\n",
    "\n",
    "        # Flush tensorboard\n",
    "        summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Train model here \n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on validation data\n",
    "precision: How many positive predictions are correct\n",
    "recall: How many positive results are predicted correctly.\n",
    "\n",
    "A higher number is a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import precision and recall \n",
    "from tensorflow.keras.metrics import Precision, Recall \n",
    "\n",
    "# Initialise precision and recall\n",
    "precision = Precision()\n",
    "recall = Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_batch in validation_data:\n",
    "    # Run the model on validation data\n",
    "    val_input, val_val, y_true = val_batch\n",
    "\n",
    "    # Predict using the model\n",
    "    yhat = siamese_model.predict([val_input, val_val])\n",
    "    precision.update_state(y_true, yhat)\n",
    "    recall.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision: {precision.result().numpy()}\")\n",
    "print(f\"Recall: {recall.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on custom test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the test data \n",
    "for (category, test_image_1, test_image_2, label) in data_raw_test:\n",
    "    p1 = tf.expand_dims(preprocess(test_image_1), axis = 0)   # Make the batch size 1\n",
    "    p2 = tf.expand_dims(preprocess(test_image_2), axis = 0)\n",
    "\n",
    "    # Make predictions and compare to ground truth\n",
    "    yhat = siamese_model.predict([p1, p2])\n",
    "    y_true = tf.convert_to_tensor([label], dtype=tf.float32)\n",
    "\n",
    "    # Postprocess them based on a threshold \n",
    "    THRESHOLD = 0.5 \n",
    "\n",
    "    print(f\"{category}\")\n",
    "    print(f\"Expected = {label}\")\n",
    "    print(f\"Predicted: {yhat >= THRESHOLD}\")\n",
    "    print(f\"Confidence: {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load the model to the \"model\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT_NAME = \"siameseModel\"\n",
    "\n",
    "siamese_model.save(MODEL_OUTPUT_NAME + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model:\n",
    "model = tf.keras.models.load_model(MODEL_OUTPUT_NAME + \".h5\", \n",
    "                                   custom_objects={\n",
    "                                       \"L1Dist\": L1Dist,    # From \"Build distance layer\" - it is a custom layer in = L1Dist()\n",
    "                                       \"contrastive_loss\": contrastive_loss\n",
    "                                       }\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the model as .tflite file\n",
    "this may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_filename = MODEL_OUTPUT_NAME + \".tflite\"\n",
    "with open(tflite_filename, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
